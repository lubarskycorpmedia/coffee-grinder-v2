# /src/services/news/runner.py

import json
import fcntl
import time
import os
import asyncio
from typing import Dict, Any, Optional, Callable, Union, List
from datetime import datetime, timezone
from contextlib import contextmanager
from pathlib import Path

import redis

from src.config import get_news_providers_settings, get_ai_settings, get_google_settings
from src.utils.input_validator import validate_api_input
from src.logger import setup_logger
from src.services.news.pipeline import NewsPipelineOrchestrator


def load_config_from_file(file_path: str) -> List[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ JSON —Ñ–∞–π–ª–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"provider": "name", "config": {...}}]
        
    Raises:
        FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        json.JSONDecodeError: –ï—Å–ª–∏ JSON –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
        ValueError: –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    """
    logger = setup_logger(__name__)
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Configuration file not found: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        config_data = json.load(f)
    
    # –¢–û–õ–¨–ö–û –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç {requests: [...]}
    if not isinstance(config_data, dict) or "requests" not in config_data:
        raise ValueError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ {{requests: [...]}}, –ø–æ–ª—É—á–µ–Ω: {type(config_data)}")
    
    logger.info("‚úÖ –ï–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {requests: [...]}")
    requests_list = config_data["requests"]
    
    if not isinstance(requests_list, list):
        raise ValueError(f"–ü–æ–ª–µ 'requests' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∞—Å—Å–∏–≤–æ–º, –ø–æ–ª—É—á–µ–Ω: {type(requests_list)}")
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    validated_list = validate_api_input(requests_list)
    
    return validated_list


class ProgressTracker:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ Redis"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_client = redis.from_url(redis_url, decode_responses=True)
        self.key = "news_processing_progress"
        
    def update_progress(self, 
                       state: str,
                       percent: int = 0,
                       current_provider: Optional[str] = None,
                       message: str = "",
                       processed_providers: Optional[list] = None,
                       start_time_override: Optional[float] = None):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ Redis"""
        current_time = datetime.now(timezone.utc)
        progress_data = {
            "state": state,  # idle|running|completed|error
            "percent": percent,
            "current_provider": current_provider or "",
            "processed_providers": json.dumps(processed_providers or []),
            "message": message,
            "timestamp": current_time.isoformat(),
        }
        
        current_progress = self.get_progress()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
        if state == "running":
            # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω start_time_override - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if start_time_override is not None:
                override_time = datetime.fromtimestamp(start_time_override, timezone.utc)
                progress_data["start_time"] = override_time.isoformat()
            else:
                # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å—Ç–∞—Ç—É—Å –±—ã–ª completed/error/idle - —ç—Ç–æ –Ω–æ–≤—ã–π –∑–∞–ø—É—Å–∫
                prev_state = current_progress.get("state", "idle")
                if prev_state in ["completed", "error", "idle"]:
                    # –ù–æ–≤—ã–π –∑–∞–ø—É—Å–∫ - —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
                    progress_data["start_time"] = current_time.isoformat()
                else:
                    # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π start_time
                    progress_data["start_time"] = current_progress.get("start_time", current_time.isoformat())
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if state in ["completed", "error"] and "start_time" in current_progress:
            progress_data["end_time"] = current_time.isoformat()
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            try:
                start_time_str = current_progress["start_time"]
                start_time = datetime.fromisoformat(start_time_str.replace("Z", "+00:00"))
                duration_seconds = (current_time - start_time).total_seconds()
                progress_data["duration"] = round(duration_seconds, 2)
            except (ValueError, KeyError) as e:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
                pass
        
        self.redis_client.hset(self.key, mapping=progress_data)
        
    def get_progress(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å"""
        data = self.redis_client.hgetall(self.key)
        if not data:
            return {
                "state": "idle",
                "percent": 0,
                "current_provider": "",
                "processed_providers": [],
                "message": "–ì–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º processed_providers –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫
        if "processed_providers" in data:
            try:
                data["processed_providers"] = json.loads(data["processed_providers"])
            except (json.JSONDecodeError, TypeError):
                data["processed_providers"] = []
        
        return data
    
    def clear_progress(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å"""
        self.redis_client.delete(self.key)


@contextmanager
def file_lock(lock_file: str, timeout: int = 300):
    """
    –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    
    Args:
        lock_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    """
    lock_path = Path(lock_file)
    lock_path.parent.mkdir(parents=True, exist_ok=True)
    
    start_time = time.time()
    
    while True:
        try:
            with open(lock_file, 'w') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                f.write(f"PID: {os.getpid()}\nStarted: {datetime.now(timezone.utc).isoformat()}\n")
                f.flush()
                
                try:
                    yield
                finally:
                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                break
                
        except IOError:
            if time.time() - start_time > timeout:
                raise RuntimeError(f"Could not acquire lock within {timeout} seconds. Process may be already running.")
            time.sleep(1)


def run_news_parsing_from_config(
    config_path: str = "data/news_parsing_config.json",
    progress_callback: Optional[Callable] = None,
    test_without_export: bool = False,
    redis_url: str = "redis://localhost:6379"
) -> Dict[str, Any]:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
    
    Args:
        config_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        test_without_export: –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Google Sheets
        redis_url: URL Redis –¥–ª—è tracking –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    # –ó–ê–ú–ï–† –í–†–ï–ú–ï–ù–ò –ù–ê–ß–ò–ù–ê–ï–¢–°–Ø –°–†–ê–ó–£ –ü–†–ò –ó–ê–ü–£–°–ö–ï
    start_time = time.time()
    
    logger = setup_logger(__name__)
    progress_tracker = ProgressTracker(redis_url)
    lock_file = "/tmp/news_processing.lock"
    
    try:
        with file_lock(lock_file):
            logger.info("üîê –ü–æ–ª—É—á–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞")
            
            # –ú–ê–†–ö–ï–† –ù–ê–ß–ê–õ–ê –û–ë–†–ê–ë–û–¢–ö–ò
            logger.info("üöÄ Pipeline started - –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            try:
                config_requests = load_config_from_file(config_path)
                logger.info(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ {config_path}")
                logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(config_requests)}")
                provider_names = [req["provider"] for req in config_requests]
                logger.info(f"üìã –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö: {provider_names}")
            except (FileNotFoundError, json.JSONDecodeError, ValueError) as e:
                error_msg = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {str(e)}"
                logger.error(error_msg)
                progress_tracker.update_progress("error", 0, message=error_msg)
                logger.error("üí• Pipeline completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –æ—à–∏–±–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                return {"success": False, "error": error_msg}
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            progress_tracker.update_progress(
                "running", 
                0, 
                message="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...",
                start_time_override=start_time
            )
            
            total_requests = len(config_requests)
            processed_requests = []
            all_results = {}
            
            for i, request in enumerate(config_requests):
                provider_name = request["provider"]
                provider_config = request["config"]
                
                current_percent = int((i / total_requests) * 100)
                request_id = f"{provider_name}_{i+1}"
                
                progress_tracker.update_progress(
                    "running",
                    current_percent,
                    current_provider=provider_name,
                    processed_providers=processed_requests,
                    message=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {i+1}/{total_requests} –¥–ª—è {provider_name}..."
                )
                
                if progress_callback:
                    progress_callback(current_percent, f"{provider_name} (–∑–∞–ø—Ä–æ—Å {i+1})")
                
                # –ú–ê–†–ö–ï–† –ù–ê–ß–ê–õ–ê –û–ë–†–ê–ë–û–¢–ö–ò –ü–†–û–í–ê–ô–î–ï–†–ê
                logger.info(f"‚ñ∂Ô∏è Starting - –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {provider_name}")
                
                try:
                    # –°–æ–∑–¥–∞–µ–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                    orchestrator = NewsPipelineOrchestrator(provider=provider_name)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                    config_dict = provider_config
                    query = config_dict.get("query", "")
                    category = config_dict.get("category", "")
                    limit = config_dict.get("limit", 50)
                    language = config_dict.get("language", "en")
                    published_after = config_dict.get("published_after")
                    published_before = config_dict.get("published_before")
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º pipeline (NOTE: test_without_export –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏)
                    result = orchestrator.run_pipeline(
                        query=query,
                        categories=[category] if category else [],
                        limit=limit,
                        language=language,
                        published_after=published_after,
                        published_before=published_before
                    )
                    all_results[request_id] = {"success": result.success, "result": result}
                    
                    if result.success:
                        logger.info(f"‚úÖ –ó–∞–ø—Ä–æ—Å {request_id} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                        # –ú–ê–†–ö–ï–† –£–°–ü–ï–®–ù–û–ì–û –ó–ê–í–ï–†–®–ï–ù–ò–Ø –ü–†–û–í–ê–ô–î–ï–†–ê
                        logger.info(f"‚úÖ Completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {request_id}")
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ {request_id}: {result.errors}")
                        # –ú–ê–†–ö–ï–† –ó–ê–í–ï–†–®–ï–ù–ò–Ø –ü–†–û–í–ê–ô–î–ï–†–ê –° –û–®–ò–ë–ö–û–ô
                        logger.error(f"‚ùå Completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –æ—à–∏–±–∫–∞–º–∏: {request_id}")
                    
                    processed_requests.append(request_id)
                    
                except Exception as e:
                    error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {request_id}: {str(e)}"
                    logger.error(error_msg)
                    all_results[request_id] = {"success": False, "error": error_msg}
                    # –ú–ê–†–ö–ï–† –ó–ê–í–ï–†–®–ï–ù–ò–Ø –ü–†–û–í–ê–ô–î–ï–†–ê –° –ò–°–ö–õ–Æ–ß–ï–ù–ò–ï–ú
                    logger.error(f"üí• Completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º: {request_id}")
                    processed_requests.append(request_id)
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            total_success = all([r.get("success", False) for r in all_results.values()])
            final_state = "completed" if total_success else "error"
            
            progress_tracker.update_progress(
                final_state,
                100,
                processed_providers=processed_requests,
                message="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞" if total_success else "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏"
            )
            
            if progress_callback:
                progress_callback(100, None)
            
            # –ú–ê–†–ö–ï–† –§–ò–ù–ê–õ–¨–ù–û–ì–û –ó–ê–í–ï–†–®–ï–ù–ò–Ø
            if total_success:
                logger.info("üèÅ Pipeline finished - –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ pipeline: –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            else:
                logger.error("üö© Pipeline finished - –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ pipeline: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
            
            return {
                "success": total_success,
                "providers_processed": len(processed_requests),
                "total_providers": total_requests,
                "results": all_results
            }
            
    except RuntimeError as e:
        error_msg = str(e)
        logger.error(f"üîí {error_msg}")
        progress_tracker.update_progress("error", 0, message=error_msg)
        # –ú–ê–†–ö–ï–† –ó–ê–í–ï–†–®–ï–ù–ò–Ø –° –û–®–ò–ë–ö–û–ô –ë–õ–û–ö–ò–†–û–í–ö–ò
        logger.error("üîí Pipeline completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞: –æ—à–∏–±–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞")
        return {"success": False, "error": error_msg}
    
    except Exception as e:
        error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
        logger.error(f"üí• {error_msg}")
        progress_tracker.update_progress("error", 0, message=error_msg)
        # –ú–ê–†–ö–ï–† –ó–ê–í–ï–†–®–ï–ù–ò–Ø –° –ö–†–ò–¢–ò–ß–ï–°–ö–û–ô –û–®–ò–ë–ö–û–ô
        logger.error("üí• Pipeline completed - –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞")
        return {"success": False, "error": error_msg}


def run_news_parsing_sync(
    config_path: str = "data/news_parsing_config.json",
    test_without_export: bool = False,
    redis_url: str = "redis://localhost:6379"
) -> Dict[str, Any]:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ cron
    """
    return run_news_parsing_from_config(
        config_path=config_path,
        test_without_export=test_without_export,
        redis_url=redis_url
    )


 