# src/services/news/fetchers/thenewsapi_com.py

import time
import random
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from .base import BaseFetcher, NewsAPIError
from ....config import get_settings
from ....logger import setup_logger


class TheNewsAPIFetcher(BaseFetcher):
    """Fetcher –¥–ª—è thenewsapi.com —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self._settings = None
        self._logger = None
        self.base_url = "https://api.thenewsapi.com/v1"
        self._session = None
    
    @property
    def settings(self):
        """–õ–µ–Ω–∏–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
        if self._settings is None:
            self._settings = get_settings()
        return self._settings
    
    @property
    def session(self):
        """–õ–µ–Ω–∏–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self._session is None:
            self._session = self._create_session()
        return self._session
    
    @property
    def logger(self):
        """–õ–µ–Ω–∏–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞"""
        if self._logger is None:
            self._logger = setup_logger(__name__)
        return self._logger
    
    def _create_session(self) -> requests.Session:
        """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ retry"""
        session = requests.Session()
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π retry - –¥–µ–ª–∞–µ–º –≤—Ä—É—á–Ω—É—é
        retry_strategy = Retry(
            total=0,
            backoff_factor=0,
            status_forcelist=[]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session
    
    def _exponential_backoff(self, attempt: int) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤—Ä–µ–º—è –∑–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ backoff"""
        base_delay = 1.0  # –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        max_delay = 60.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        
        delay = base_delay * (self.settings.BACKOFF_FACTOR ** attempt) + random.uniform(0, 1)
        return min(delay, max_delay)
    
    def _make_request(self, endpoint: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç HTTP –∑–∞–ø—Ä–æ—Å —Å retry –ª–æ–≥–∏–∫–æ–π"""
        url = f"{self.base_url}/{endpoint}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º API —Ç–æ–∫–µ–Ω –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        params["api_token"] = self.settings.THENEWSAPI_API_TOKEN
        
        headers = {
            "User-Agent": "coffee-grinder-news-service/1.0",
            "Accept": "application/json"
        }
        
        last_error = None
        
        for attempt in range(self.settings.MAX_RETRIES):
            try:
                # –ú–∞—Å–∫–∏—Ä—É–µ–º API —Ç–æ–∫–µ–Ω –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                safe_params = params.copy()
                if 'api_token' in safe_params:
                    token = safe_params['api_token']
                    safe_params['api_token'] = f"{token[:8]}...{token[-4:]}" if len(token) > 12 else "***"
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL –∑–∞–ø—Ä–æ—Å–∞
                query_string = "&".join([f"{k}={v}" for k, v in safe_params.items()])
                full_url = f"{url}?{query_string}"
                
                self.logger.info(f"üåê GET {full_url}")
                self.logger.info(f"üì§ Attempt {attempt + 1}/{self.settings.MAX_RETRIES}")
                
                response = self.session.get(
                    url,
                    params=params,
                    headers=headers,
                    timeout=30
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –æ—Ç–≤–µ—Ç–∞
                self.logger.info(f"üì• Response: {response.status_code} {response.reason}")
                self.logger.info(f"üìä Content-Type: {response.headers.get('content-type', 'N/A')}")
                self.logger.info(f"üìä Content-Length: {response.headers.get('content-length', 'N/A')} bytes")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–¥
                if response.status_code == 200:
                    data = response.json()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ
                    if "error" in data:
                        error_info = data["error"]
                        error_msg = error_info.get("message", "Unknown API error")
                        self.logger.error(f"API error: {error_msg}")
                        last_error = NewsAPIError(error_msg, response.status_code, attempt + 1)
                        return {"error": last_error}
                    
                    # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
                    total_results = len(data.get("data", []))
                    self.logger.info(f"Successfully fetched {total_results} items")
                    return data
                    
                elif response.status_code == 429:
                    # Rate limit exceeded
                    self.logger.warning(f"Rate limit exceeded (429), attempt {attempt + 1}/{self.settings.MAX_RETRIES}")
                    last_error = NewsAPIError("Rate limit exceeded", 429, attempt + 1)
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –∂–¥–µ–º
                    if attempt < self.settings.MAX_RETRIES - 1:
                        delay = self._exponential_backoff(attempt)
                        self.logger.info(f"Waiting {delay:.2f} seconds before retry...")
                        time.sleep(delay)
                        continue
                    else:
                        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                        self.logger.error(f"Rate limit exceeded after {self.settings.MAX_RETRIES} attempts")
                        return {"error": last_error}
                
                else:
                    # –î—Ä—É–≥–∏–µ HTTP –æ—à–∏–±–∫–∏
                    try:
                        error_data = response.json()
                        if "error" in error_data:
                            error_msg = error_data["error"].get("message", f"HTTP {response.status_code}")
                        else:
                            error_msg = f"HTTP {response.status_code}: {response.text}"
                    except:
                        error_msg = f"HTTP {response.status_code}: {response.text}"
                    
                    self.logger.error(error_msg)
                    last_error = NewsAPIError(error_msg, response.status_code, attempt + 1)
                    
                    # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω—ã—Ö –æ—à–∏–±–æ–∫ (5xx) –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
                    if 500 <= response.status_code < 600 and attempt < self.settings.MAX_RETRIES - 1:
                        delay = self._exponential_backoff(attempt)
                        self.logger.info(f"Server error, waiting {delay:.2f} seconds before retry...")
                        time.sleep(delay)
                        continue
                    else:
                        return {"error": last_error}
                        
            except requests.exceptions.RequestException as e:
                error_msg = f"Request failed: {str(e)}"
                self.logger.error(error_msg)
                last_error = NewsAPIError(error_msg, None, attempt + 1)
                
                # –î–ª—è —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
                if attempt < self.settings.MAX_RETRIES - 1:
                    delay = self._exponential_backoff(attempt)
                    self.logger.info(f"Network error, waiting {delay:.2f} seconds before retry...")
                    time.sleep(delay)
                    continue
                else:
                    return {"error": last_error}
        
        # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –∑–Ω–∞—á–∏—Ç –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        return {"error": last_error}
    
    def fetch_headlines(self, 
                       locale: Optional[str] = "us",
                       language: Optional[str] = "en",
                       domains: Optional[str] = None,
                       exclude_domains: Optional[str] = None,
                       source_ids: Optional[str] = None,
                       exclude_source_ids: Optional[str] = None,
                       published_on: Optional[str] = None,
                       headlines_per_category: int = 6,
                       include_similar: bool = True) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        
        Args:
            locale: –ö–æ–¥—ã —Å—Ç—Ä–∞–Ω —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (us, ca, etc.)
            language: –ö–æ–¥—ã —è–∑—ã–∫–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (en, es, etc.)
            domains: –î–æ–º–µ–Ω—ã –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_domains: –î–æ–º–µ–Ω—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            published_on: –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (YYYY-MM-DD)
            headlines_per_category: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (max 10)
            include_similar: –í–∫–ª—é—á–∞—Ç—å –ø–æ—Ö–æ–∂–∏–µ —Å—Ç–∞—Ç—å–∏
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        params = {
            "headlines_per_category": min(headlines_per_category, 10),
            "include_similar": str(include_similar).lower()
        }
        
        if locale:
            params["locale"] = locale
        if language:
            params["language"] = language
        if domains:
            params["domains"] = domains
        if exclude_domains:
            params["exclude_domains"] = exclude_domains
        if source_ids:
            params["source_ids"] = source_ids
        if exclude_source_ids:
            params["exclude_source_ids"] = exclude_source_ids
        if published_on:
            params["published_on"] = published_on
            
        return self._make_request("news/headlines", params)
    
    def fetch_all_news(self,
                      search: Optional[str] = None,
                      locale: Optional[str] = None,
                      language: Optional[str] = None,
                      domains: Optional[str] = None,
                      exclude_domains: Optional[str] = None,
                      source_ids: Optional[str] = None,
                      exclude_source_ids: Optional[str] = None,
                      categories: Optional[str] = None,
                      exclude_categories: Optional[str] = None,
                      published_after: Optional[str] = None,
                      published_before: Optional[str] = None,
                      published_on: Optional[str] = None,
                      sort: str = "published_at",
                      sort_order: str = "desc",
                      limit: int = 100,
                      page: int = 1) -> Dict[str, Any]:
        """
        –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º –Ω–æ–≤–æ—Å—Ç—è–º
        
        Args:
            search: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ (+, -, |, —Å–∫–æ–±–∫–∏)
            locale: –ö–æ–¥—ã —Å—Ç—Ä–∞–Ω —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            language: –ö–æ–¥—ã —è–∑—ã–∫–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            domains: –î–æ–º–µ–Ω—ã –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_domains: –î–æ–º–µ–Ω—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            published_after: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (YYYY-MM-DD)
            published_before: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è (YYYY-MM-DD)
            published_on: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)
            sort: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (published_at, relevance_score)
            sort_order: –ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (asc, desc)
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (max 100)
            page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        params = {
            "sort": sort,
            "sort_order": sort_order,
            "limit": min(limit, 100),
            "page": page
        }
        
        if search:
            params["search"] = search
        if locale:
            params["locale"] = locale
        if language:
            params["language"] = language
        if domains:
            params["domains"] = domains
        if exclude_domains:
            params["exclude_domains"] = exclude_domains
        if source_ids:
            params["source_ids"] = source_ids
        if exclude_source_ids:
            params["exclude_source_ids"] = exclude_source_ids
        if categories:
            params["categories"] = categories
        if exclude_categories:
            params["exclude_categories"] = exclude_categories
        if published_after:
            params["published_after"] = published_after
        if published_before:
            params["published_before"] = published_before
        if published_on:
            params["published_on"] = published_on
            
        return self._make_request("news/all", params)
    
    def fetch_top_stories(self,
                         locale: Optional[str] = "us",
                         language: Optional[str] = "en",
                         domains: Optional[str] = None,
                         exclude_domains: Optional[str] = None,
                         source_ids: Optional[str] = None,
                         exclude_source_ids: Optional[str] = None,
                         categories: Optional[str] = None,
                         exclude_categories: Optional[str] = None,
                         published_after: Optional[str] = None,
                         published_before: Optional[str] = None,
                         published_on: Optional[str] = None,
                         limit: int = 100,
                         page: int = 1) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–ø –Ω–æ–≤–æ—Å—Ç–∏
        
        Args:
            locale: –ö–æ–¥—ã —Å—Ç—Ä–∞–Ω —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            language: –ö–æ–¥—ã —è–∑—ã–∫–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            domains: –î–æ–º–µ–Ω—ã –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_domains: –î–æ–º–µ–Ω—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_source_ids: ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            exclude_categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            published_after: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (YYYY-MM-DD)
            published_before: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è (YYYY-MM-DD)
            published_on: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (max 100)
            page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        params = {
            "limit": min(limit, 100),
            "page": page
        }
        
        if locale:
            params["locale"] = locale
        if language:
            params["language"] = language
        if domains:
            params["domains"] = domains
        if exclude_domains:
            params["exclude_domains"] = exclude_domains
        if source_ids:
            params["source_ids"] = source_ids
        if exclude_source_ids:
            params["exclude_source_ids"] = exclude_source_ids
        if categories:
            params["categories"] = categories
        if exclude_categories:
            params["exclude_categories"] = exclude_categories
        if published_after:
            params["published_after"] = published_after
        if published_before:
            params["published_before"] = published_before
        if published_on:
            params["published_on"] = published_on
            
        return self._make_request("news/top", params)
    
    def get_sources(self,
                   locale: Optional[str] = None,
                   language: Optional[str] = None,
                   categories: Optional[str] = None) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        
        Args:
            locale: –ö–æ–¥—ã —Å—Ç—Ä–∞–Ω —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            language: –ö–æ–¥—ã —è–∑—ã–∫–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        params = {}
        
        if locale:
            params["locale"] = locale
        if language:
            params["language"] = language
        if categories:
            params["categories"] = categories
            
        return self._make_request("news/sources", params)
    
    def fetch_recent_tech_news(self, days_back: int = 1) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
        
        Args:
            days_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        published_after = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")
        
        return self.fetch_all_news(
            search="technology + (AI | artificial intelligence | machine learning | startup)",
            language="en",
            categories="tech,business",
            published_after=published_after,
            sort="relevance_score",
            sort_order="desc",
            limit=100
        ) 